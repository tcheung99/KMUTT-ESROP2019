{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-595e1d15064d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Finally, execute the following cell to show the version of TensorFlow that is used in this lab.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Let's execute the cell below to display information about the GPUs running on the server.\n",
    "!nvidia-smi\n",
    "\n",
    "# Finally, execute the following cell to show the version of TensorFlow that is used in this lab.\n",
    "import tensorflow as tf; \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f4a28d693ea2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m \u001b[1;31m# NLU library\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0men\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEnglish\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy # NLU library\n",
    "spacy.load('en_core_web_sm')\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "import en_core_web_lg # Large SpaCy model for English language\n",
    "import numpy as np\n",
    "import re # regular expressions\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC # Support Vector Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_format = \"User: {input}\\nSITA: {output}\\n\" + \"_\"*50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Use exact matchesÂ¶\n",
    "\n",
    "hard-coded exact questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard-coded exact questions\n",
    "responses_exact = {\n",
    "    \"what would you like to eat tonight?\": \"Pasta with salmon and red pesto please!\",\n",
    "    \"what time will you be home tonight?\": \"I will be home around 6 pm.\",\n",
    "    \"default\": \"I love you too!\"\n",
    "}\n",
    "\n",
    "def respond_exact(text):\n",
    "    response = responses_exact.get(text.lower(), responses_exact['default'])\n",
    "    return(output_format.format(input=text, output=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What would you like to eat tonight?\n",
      "SITA: Pasta with salmon and red pesto please!\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "User: What time will you be home tonight?\n",
      "SITA: I will be home around 6 pm.\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "User: I just found out my boss is leaving the company.\n",
      "SITA: I love you too!\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(respond_exact(\"What would you like to eat tonight?\"))\n",
    "print(\"_\"*50)\n",
    "print(respond_exact(\"What time will you be home tonight?\"))\n",
    "print(\"_\"*50)\n",
    "print(respond_exact(\"I just found out my boss is leaving the company.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Pattern Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keywords that can help determine the intent \n",
    "intent_keywords = {\n",
    "    'dinner_preference': ['eat', 'dinner', 'food', 'cook', 'craving'],\n",
    "    'arrival_time': ['time', 'when', 'get here', 'be home']\n",
    "}\n",
    "# Create a dictionary of patterns\n",
    "patterns = {intent: re.compile('|'.join(keys)) for intent, keys in intent_keywords.items()}\n",
    "\n",
    "# Define a function to find the intent of a message\n",
    "def get_intent_re(message):\n",
    "    for intent, pattern in patterns.items():\n",
    "        # Check if the pattern occurs in the message \n",
    "        if pattern.search(message):\n",
    "            return(intent)\n",
    "    else:\n",
    "        return('default')\n",
    "\n",
    "responses_re = {\n",
    "    \"dinner_preference\":\"Pasta with salmon and red pesto please!\",\n",
    "    \"arrival_time\": \"I will be home around 6 pm.\",\n",
    "    \"default\":\"I like you too!\"\n",
    "}\n",
    "\n",
    "def respond_re(text):\n",
    "    response = responses_re.get(get_intent_re(text))\n",
    "    return(output_format.format(input=text, output=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what would you like to eat tonight?\n",
      "SITA: Pasta with salmon and red pesto please!\n",
      "__________________________________________________\n",
      "User: what time will you be home tonight?\n",
      "SITA: I will be home around 6 pm.\n",
      "__________________________________________________\n",
      "User: I just food out my boss is leaving the company.\n",
      "SITA: Pasta with salmon and red pesto please!\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(respond_re(\"what would you like to eat tonight?\"))\n",
    "print(respond_re(\"what time will you be home tonight?\"))\n",
    "print(respond_re(\"I just food out my boss is leaving the company.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data\n",
    "training_sentences = [\n",
    "    \"What would you like to have for dinner?\",\n",
    "    \"What do you want to eat tonight?\",\n",
    "    \"I don't know what to cook tonight.\",\n",
    "    \"Do you have any cravings?\",\n",
    "    \"Can I get you something to eat?\", \n",
    "    \"What time will you be home?\",\n",
    "    \"How much longer will you be?\",\n",
    "    \"When can we expect you to get here?\",\n",
    "    \"What's taking you so long?\",\n",
    "    \"At what hour will you be here?\"\n",
    "    \n",
    "]\n",
    "training_intents = [\n",
    "    \"dinner_preference\",\n",
    "    \"dinner_preference\",\n",
    "    \"dinner_preference\",\n",
    "    \"dinner_preference\",\n",
    "    \"dinner_preference\",\n",
    "    \"arrival_time\",\n",
    "    \"arrival_time\",\n",
    "    \"arrival_time\",\n",
    "    \"arrival_time\",\n",
    "    \"arrival_time\"   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may take a couple of seconds\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the array with zeros: X\n",
    "X_train = np.zeros((len(training_sentences), \n",
    "              nlp('sentences').vocab.vectors_length))\n",
    "\n",
    "for i, sentence in enumerate(training_sentences):\n",
    "    # Pass each each sentence to the nlp object to create a document\n",
    "    doc = nlp(sentence)\n",
    "    # Save the document's .vector attribute to the corresponding row in X\n",
    "    X_train[i, :] = doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a support vector classifier\n",
    "clf = SVC(C=1, gamma=\"auto\", probability=True)\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "clf.fit(X_train, training_intents)\n",
    "\n",
    "#Yes, a lot can be done here to check / improve model performance! We will leave that for another day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent_ml(text):\n",
    "    doc = nlp(text)\n",
    "    return(clf.predict([doc.vector])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how to deal with it.\n",
    "responses_ml = {\n",
    "    \"dinner_preference\":\"Pasta with salmon and red pesto please!\",\n",
    "    \"arrival_time\": \"I will be home around 6 pm.\",\n",
    "    \"default\":\"I like you too!\"\n",
    "}\n",
    "\n",
    "def respond_ml(text):\n",
    "    response = responses_ml.get(get_intent_ml(text), responses_ml[\"default\"])\n",
    "    return(output_format.format(input=text, output=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what would you like to eat tonight?\n",
      "SITA: Pasta with salmon and red pesto please!\n",
      "__________________________________________________\n",
      "User: what time will you be home tonight?\n",
      "SITA: I will be home around 6 pm.\n",
      "__________________________________________________\n",
      "User: l\n",
      "SITA: Pasta with salmon and red pesto please!\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(respond_ml(\"what would you like to eat tonight?\"))\n",
    "print(respond_ml(\"what time will you be home tonight?\"))\n",
    "print(respond_ml(\"l\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_intent_ml_2(text):\n",
    "    \"\"\"\n",
    "        Returns the intent from a given text, unless the model is not sure, in which case 'default' is returned\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    max_proba = max(clf.predict_proba([doc.vector])[0])\n",
    "    if(max_proba == 0.5):\n",
    "        return('default')\n",
    "    else:\n",
    "        return(clf.predict([doc.vector])[0])\n",
    "\n",
    "def respond_ml_2(text):\n",
    "    response = responses_ml.get(get_intent_ml_2(text), responses_ml[\"default\"])\n",
    "    return(output_format.format(input=text, output=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: flowers\n",
      "SITA: Pasta with salmon and red pesto please!\n",
      "__________________________________________________\n",
      "User: flowers\n",
      "SITA: I like you too!\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(respond_ml(  'flowers'))\n",
    "print(respond_ml_2('flowers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_entities(text):\n",
    "    \"\"\"\n",
    "        Get all entities in a given text, in a text: label_ dictionary\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    d = defaultdict(list)\n",
    "    for ent in doc.ents:\n",
    "        d[ent.label_].append(ent.text)\n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('DATE', ['next tuesday', 'wednesday']), ('GPE', ['Bengals']), ('TIME', ['tonight'])]\n"
     ]
    }
   ],
   "source": [
    "test_ents = get_all_entities('what would you like to eat tonight?, or next tuesday or wednesday fish football Bengals')\n",
    "print(sorted(test_ents.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = {\n",
    "    (\"dinner_preference\", \"time and date\"): \"I want to eat pasta\",\n",
    "    (\"dinner_preference\", \"time only\"): \"I want to eat pasta\",\n",
    "    (\"dinner_preference\", \"date only\"): \"I want to eat pasta\",\n",
    "    (\"dinner_preference\", \"none\"): \"When?\",\n",
    "    (\"arrival_time\", \"time and date\"): \"I will be home at six\",\n",
    "    (\"arrival_time\", \"time only\"): \"I will be home at six\",\n",
    "    (\"arrival_time\", \"date only\"): \"I will be home at six\",\n",
    "    (\"arrival_time\", \"none\"): \"When?\",\n",
    "    (\"default\", \"none\"): \"What do you want?\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond_ml_3(text):\n",
    "    \"\"\"Check for specification of date and time\n",
    "        If not specified, ask for clarification\n",
    "    \"\"\"\n",
    "    intent = get_intent_ml_2(text)\n",
    "        \n",
    "    if intent != 'default':\n",
    "        entities = get_all_entities(text)\n",
    "        if 'TIME' in entities and 'DATE' in entities:\n",
    "            specification = 'time and date'\n",
    "            time = ' and '.join(entities['DATE']) + ' at ' + ' and '.join(entities['TIME'])\n",
    "        elif 'TIME' in entities:\n",
    "            specification = 'time only'\n",
    "            time = ' and '.join(entities['TIME'])\n",
    "        elif 'DATE' in entities:\n",
    "            specification = 'date only'\n",
    "            time = ' and '.join(entities['DATE'])\n",
    "        else:\n",
    "            specification = 'none'\n",
    "            time = \"\"\n",
    "    else:\n",
    "        specification = 'none'\n",
    "        time = \"\"\n",
    "    \n",
    "    response = policy.get((intent, specification)) + ' ' + time\n",
    "    return(output_format.format(input=text, output=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what would you like to eat next wednesday thursday and friday?\n",
      "SITA: I want to eat pasta thursday and friday\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(respond_ml_3('what would you like to eat next wednesday thursday and friday?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your last birthday\n",
      "when me went to florida\n",
      "i had your own castle\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Define replace_pronouns()\n",
    "def replace_pronouns(message):\n",
    "    message = message.lower()\n",
    "    \n",
    "    if 'me' in message:\n",
    "        # Replace 'me' with 'you'\n",
    "        return re.sub('me', 'you', message)\n",
    "    if 'my' in message:\n",
    "        # Replace 'my' with 'your'\n",
    "        return re.sub('my', 'your' ,message)\n",
    "    if 'your' in message:\n",
    "        # Replace 'your' with 'my'\n",
    "        return re.sub('your','my',message)\n",
    "    if 'you' in message:\n",
    "        # Replace 'you' with 'me'\n",
    "        return re.sub('you', 'me',message)\n",
    "\n",
    "    return message\n",
    "\n",
    "print(replace_pronouns(\"my last birthday\"))\n",
    "print(replace_pronouns(\"when you went to Florida\"))\n",
    "print(replace_pronouns(\"I had my own castle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
